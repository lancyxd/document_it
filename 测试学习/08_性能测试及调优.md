# 1 性能测试目的

目的：通过性能测试，发现系统瓶颈，识别系统中的弱点，评估系统的能力，验证系统的稳定性和可靠性。以推动**系统调优**。

备注：以真实的业务为依据，选择具有代表性的、关键的业务操作设计测试案例，以评价系统的当前性能。通过模拟成百上千个用户，重复执行和运行测试，可以确定性能瓶颈并优化和调整应用，目的在于通过大负荷或者针对性的场景下发掘系统潜在问题，分析并找到优化方案，达到提升系统性能的目的。

- 性能瓶颈

  硬件：cpu、内存、磁盘IO等。

  操作系统：物理内存不足，虚拟内存设计不合理等。

  中间件：mysql、kafka中间件等参数优化配置等。

  网络瓶颈：一般指的是防火墙、动态负载均衡器、交换机等设备。 

  应用程序：程序自身的逻辑，尽量考虑到缓存和并发、多线程。

- 测试目标：性能测试所解决的问题

  硬件选型(硬件服务器等选型)；

  用户体验；

  性能验收(提供符合当初提出性能要求的报告才能验收通过);

  用户增加(几个月后，该系统用户大幅增加，支撑那么多的用户访问，是调整硬件还是软件？)；

  性能瓶颈(什么原因导致的性能达不到预期？)；

  系统稳定性(试运行和测试环境一直运行稳定，上线后，实际用户环境出故障，卡死等？)

  部署效果(系统上线，如何部署最佳?)

# 2 性能测试指标

## 2.1响应时间

- **响应时间**：客户端发请求到得到响应的整个过程所耗费的时间。TTLB（Timeto Laster Byte），从发起一个请求开始，到客户端收到最后一个字节的响应所耗费的时间。主要包括：

1）数据网络传输耗时：请求、响应数据在网络中传输消耗的时间，和网络的时延、带宽有关系。；

2）服务器处理耗时：系统收到请求后，对其处理，并将结果返回的时间，和系统服务器的软硬件配置有关；

3）呈现时间：主要是浏览器对接收的数据的渲染展示过程，与浏览器、操作系统和电脑硬件配置等都有关。

- **测试分类（按响应时间）**

  1）接口：接口响应时间只包含数据传输时间、系统处理时间，不包括呈现时间。jmeter支持该类响应时间的统计，共有min、max、avg三种统计结果。

  2）web页面：web页面想用时间统计（浏览器抓包工具统计页面响应时间；录屏软件抓取屏幕计算响应时间；JS打点统计页面响应时间）

- **测试分析（分析原则）**

    - 响应时间的2/5/8原则

      当用户能够在2秒以内得到响应时，会感觉系统的响应很快；

      当用户在2-5秒之间得到响应时，会感觉系统的响应速度还可以；

      当用户在5-8秒以内得到响应时，会感觉系统的响应速度很慢，但是还可以接受；

      而当用户在超过8秒后仍然无法得到响应时，会感觉系统糟透了，或者认为系统已经失去响应，而选择离开这个Web站点，或者发起第二次请求。

    - 参考标准(响应时间的百分比指标做参考)

      1）普通响应时间：5S内；万级响应时间：8s内；百万级响应时间：10s内；千万级响应时间20s内。
      
      2）响应时间的标准一般定义：99.9%响应时间必须在100ms以下（非平均值，99.9%取样响应时间均在  100ms以下）或者平均响应时间在100ms以下，目前工具只能统计平均响应时间指标。 
      
      3）当前系统实测响应时间指标不得高于历史版本的实测结果（在相同条件进行测试结果的比较）。
      
      4）新系统，无历史版本参考时，可参考同类系统功能的响应时间实测结果。 


## 2.2 TPS(QPS)、并发用户数

- **定义**

  TPS：每秒事务数，指系统每秒能够处理的事务数量（一个事务可能是有多个请求组成）。 

  QPS：每秒查询率，指系统每秒能够处理的查询（通常指一个request请求）数量。 

  并发用户数：在同一时刻（任一时刻）与服务器进行交互（服务器正在处理）的在线用户的数量。对于并发用户数避免两种错误的理解，一种错误的理解是把并发用户数理解为系统注册用户数，还有一个错误的理解是把并发用户数理解为系统在线用户数。

- **分析评估**

  1）最大吞吐量和系统资源使用的分析： 在明确响应时间要求的限制下，压力测试过程中，找到最大吞吐量的拐点时，分析系统资源（CPU、内存）的使用率，若使用率过低，则继续加大并发用户量，若系统的所有节点的任一资源均无法达到70%使用率，说明系统存在系统类、软件类问题和瓶颈，需要调优。 

  二、TPS与需求规格定义（生产环境负载）比较 

  1) 需求规格说明书中有明确的标准定义  将吞吐量的实测结果和需求规格定义（生产环境负载）比较，若大于需求规格定义则为通过。一般最大吞吐量对应生产环境的平均负载，系统极限值仅用来应对生产环境的突发高峰。 

  2) 需求规格说明书中需明确相关性能指标。  性能指标可参考生产环境交易量统计数据来评估，评估结果一般应略高于当前生产环境的负载（预留半年到一年访问量增长的余量）。  若新开发产品，无生产环境度量数据，可参考同类产品、本产品运营推广计划来评估本产品的性能指标，性能指标确认的结果可通过提单结论归档。 

  3）负载测试、稳定性测试采样分析 在负载测试、稳定性测试过程中，保持最高吞吐量情况下压测，TPS曲线、响应时间曲线应该是趋于稳定的，如出现大的波动（骤升或骤降），则视为异常的拐点（问题），需要进行问题定位。

## 2.3 成功率

标准要求：负载测试、稳定性测试，请求成功率要求大于99.9%（根据实际情况和业务评估要求）。

## 2.4 资源使用率

- **资源使用率相关定义**

  - cpu使用率：CPU时间的百分比，通常认为CPU使用率是us（用户态）+sy（系统态）使用CPU百分比之和。

    us 用户空间占用CPU百分比

    sy 内核空间占用CPU百分比
    ni 用户进程空间内改变过优先级的进程占用CPU百分比
    id 空闲CPU百分比
    wa 等待输入输出的CPU时间百分比
    hi：硬件CPU中断占用百分比
    si：软中断占用百分比
    st：虚拟机占用百分比

  - 内存使用率，**可用内存=free+buffer+cached** 
  
    Mem 行(第二行)是内存的使用情况。
    Swap 行(第三行)是交换空间的使用情况。
    total 列显示系统总的可用物理内存和交换空间大小。
    used 列显示已经被使用的物理内存和交换空间。
    free 列显示还有多少物理内存和交换空间可用使用。
    shared 列显示被共享使用的物理内存大小。
    buff/cache 列显示被 buffer 和 cache 使用的物理内存大小。
    available 列显示还可以被应用程序使用的物理内存大小。
  
  - IOWAIT
  
    [性能监控 sar命令](https://blog.csdn.net/liyongbing1122/article/details/89517282)

- **资源使用率测试方法(采用nmon工具监控)**

  1）Nmon。全面监控linux系统资源使用情况，包括CPU、内存、I/O等，可独立于应用监控。通过Nmon采集记录（可以同时监控CPU、内存、IO等各种丰富的性能资源指标），可以持续记录测试过程每个时间点的资源使用情况，对于多核系统，也可以分别监控每个CPU的使用情况。可通过Nmon采集的资源使用曲线、结合系统的性能表现，初步完成系统的评估（判断是否存在问题）。 

  2）通过Linux命令来进行系统问题分析

  top：查看进程活动状态以及一些系统状况，没办法记录所有时间点的资源使用情 况，好处是可以查看到进程级别的资源使用。

  vmstat：查看系统状态、硬件和系统信息等，通过vmstat查询，查询整体的CPU 使用情况，同时也可以查询进程、内存、交换页面、IO的情况。

  iostat：查看CPU 负载，硬盘状况 

  sar(同类的tsar阿里开源工具）：综合类工具，比较全面的查看系统状况的工具， 如文件的读写情况、系统调用的使用情况、磁盘I/O、CPU效率、内存使用状况、进程活动及IPC有关的活动。 

  mpstat：多核CPU的可以通过该命令查看某个cpu的情况 

  netstat：查看网路情况 

  tcpdump\tcptrace：抓取网络数据包和分析网络数据包工具 

  dstat：综合工具，综合了 vmstat, iostat, ifstat, netstat 等多个信息 

  ps：进程查询工具

- **资源使用率分析评估**

  1）通过比较“最大吞吐量”和“系统资源使用率”之间的关系进行分析，系统必须在CPU、内存资源使用小于70%的情况下，提供最大的吞吐量和用户能接受的响应时间限制。

  2）通过并发量的增加和资源使用率的增加比较分析，判断并发的资源开销，通过历史经验对比判断资源消耗是否过高。 
  
  3）负载测试、稳定性测试长时间运行，CPU、内存使用率不的超过70%。 
  
  4）通过IO Wait值初步判断，一般将IO Wait指标的标准定为2，但并不是说IO Wait超过2就是有问题，而是作为条件触发测试人员检查IO对业务是否有影响，如果对业务没有影响，就不算问题，如果有影响就进一步分析IO的问题。

# 3 测试方法

- **前提：**网络环境稳定（场景一：建议施压设备和被测系统在同一局域网测试；场景二：施压设备和被测系统在不同的机房环境中通过公网测试）；确定一定的并发量来测试响应时间（最优并发用户场景、最高并发用户场景两种场景测试，响应时间的表现是不同的，最高并发场景的响应时间将会比最优并发的响应时间大得多，测试前需确定测试场景是最优并发还是最高并发）。

- **步骤**

  1）找到最高的吞吐量tps

  - 测试前确定一个响应时间的标准（如：小于100ms），然后进行基准测试，通过虚 拟并发用户数为1的方式测试，记录测试的TPS、响应时间测试结果，将该响应时间与标准比较，若大于标准响应时间，那么则说明系统有问题无法满足标准，若该响应时间小于标准时间，则继续下面的测试。  
  - 通过压力测试找到最大的吞吐量：在基准测试响应时间的限制下，找到系统最大的 吞吐量（TPS），该状况下响应时间满足要求、吞吐量最大，可确定为“最佳并发用户数”。方法是按照一定的步长，不断增加虚拟并发用户数，直至响应时间超过限制、吞吐量不在增长、任意节点资源使用率超过要求（如：70%）。  

  2）负载测试：保持最大吞吐量，执行负载测试，持续30分钟，记录测试TPS、响应时间 测试结果。 

  3）稳定性测试：保持最大吞吐量，执行稳定性测试，持续3*24小时，记录测试TPS、响应时间。

  4) 在成功率100%的限制下（不考虑响应时间长短）找到系统的极限值。不断增加并发用 户数，能够持续运行30分钟不出错误的并发量即为系统的极限值。


# 4 测试工具

- **测试工具**： jmeter

- **监控工具：**Pinpoint，zabbix

- **分析工具：**性能分析工具-JMC，Java性能分析神器-JProfiler



#   5 性能优化方法

- **慢sql优化**

  数据库建索引；数据库结构的设计；分解关联查询(大查询分解多个小查询)；分库分表；

- **中间件配置优化和调优**

  按照官方建议对配置文件进行优化和调优处理。

- **其它**

  采用消息队列，异步处理。采用缓存（先访问缓存，缓存命中不到，再访问数据库）；sql语句优化；代码业务逻辑的优化。加锁处理时，尽可能缩小锁的范围；文件名重复（获取相似文件名优于获取全部文件的文件名）；